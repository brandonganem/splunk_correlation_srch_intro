= Correlation Search Design
Brandon Ganem <bganem@aplura.com>
:date: April 24, 2017
// :backend: deckjs
:deckjs_transition: fade
:theme:
:navigation:
:menu:
:split:
:toc: left
:icons: front
:imagesdir: ./images
:url-aplura: http://www.aplura.com
// This is in place for the attributes section
:Aplura: Aplura
:prod: Splunk
:lead: mailto:bganem@aplura.com[Brandon Ganem]


ifeval::["{backend}" == "html5"]
[discrete]
== Title Page

{doctitle}

{firstname} {lastname}

{email}
endif::[]

== Overview

* What is a Correlation Search?
* Brainstorming // Correlation Search Ideas
* Building the Search
* Entry into Content Management
* Drilldown Creation
* Extra Credit

== What is a Correlation Search?

I like to think of Correlation Searches are regular saved searches with additional scaffolding added.

ES <=4.5 - correlationsearches.conf provides the scaffolding.

ES >4.5 - correlationsearches.conf has been removed and merged back into savedsearches.conf.
It really is just a saved search!

== Brainstorming // Correlation Search Ideas

Reasons for creating a Correlation Search:

* Replace an existing Correlation Search with one tailored for the environment
* Additional alerting an organization's strength's and weaknesses
** Leverage good visibility on endpoints to aid lack of visibility on the network
* Custom datasources that don't fit into a CIM datamodel

<<<<

For this presentation I'll be working walking through the steps to replace the built in "Access - Brute Force Access Behavior Detected - Rule" search that Splunk Enterprise Security ships with.
If I'm being honest, I've never been much of a fan of this search and I've heard others have the same complaint, so let's come up with something better.

<<<<

The built in correlation search isn't particularly smart.
A generous reading of what the search could go something like so:

"Detects excessive number of failed login attempts along with a successful attempt (this could indicate a successful brute force attack)"

[%step]
** Yes, I swiped that from the description.

[%step]
A less generous reading:

[%step]
This search simply counts the number of successes and failures by user and compares the number of failures to an extreme search context.
There is no concept of time order, just the requirement of some number of failures plus one or more successes.
So long as the number of failures is greater than the threshold set by the Extreme Search context, a notable event is created.

<<<<

In my experience that isn't useful.

image::firehose.jpg[]
//[.canvas-caption, position=center]

== Some alternatives
* A number of failures followed by a success within a timespan
* User account spraying
* Password spraying

Some more advanced ideas

* Admin account logged into a new system, followed by many login attempts by that account
** Maybe expand this to lessor privileged users too?
** For a good datasource here, check out special group auditing in Windows (it's pretty neat)
* Executable mimetype download followed by an authentication spike

While these examples are focused on authentication, I think it's pretty clear how they can be expanded to other datasources.

== Building the Search

Let's break this down into bite size chunks.

* `| tsats syntax`
** Or how to return data from an accelerated datamodel
* Some stats-fu
* Fields that belong in a notable event

== | tstats

// Create a color coded, broken out tstats command here
`| tstats <stats func> where <restraint> by <field list, time & span>`

So stepping through it:
[%step]
What do we want to do to the data?

[%step]
 | tstats count, dc(Authentication.dest) AS dc_dest

[%step]
Where is the data coming from?

[%step]
 from datamodel=Authentication.Authentication

[%step]
Our stats aggregation clause:

[%step]
 by Authentication.action, Authentication.src, Authentication.user, _time span=1m

[%step]
Lastly, lets drop the datamodel name:

[%step]
 |`drop_dm_object_name("Authentication")`

== Stats-fu & filtering
Let's add some additional logic to our search:

 | streamstats sum(eval(match(action,"failure"))) as action_count reset_after="("match(action,\"success\")")" by user

Filtering:

 | where match(action,"success") AND action_count>=4

For further reading, check out Kyle Smith's talk on http://conf.splunk.com/files/2016/slides/lesser-known-search-commands.pdf[Lesser Known Search Commands]

== Final result formatting

Let's take filtered results and table them out into the fields we would like to include in our notabe event.
While you do have the ability to add displayed fields in incident review, if we have a value that makes sense in an already displayed field then we should use it!

=== Putting it all together

 | tstats count, dc(Authentication.dest) AS dc_dest from datamodel=Authentication.Authentication by Authentication.action, Authentication.src, Authentication.user, _time span=1m | `drop_dm_object_name("Authentication")` | streamstats sum(eval(match(action,"failure"))) as action_count reset_after="("match(action,\"success\")")" by user | where match(action,"success") AND action_count>=4 | table _time, user, src, dc_dest, action_count

== Entry into Content Management

Naming scheme ideas:

* <Security Domain>-<Name>
** Auth-Brute_force_succeeded
* <Security Domain>-<Name>-<Timespan>
** Auth-Brute_force_succeeded-1h

I'm a big fan of something that sticks out as a custom search.
Beyond that, pick something consistent for, it will make it easier to manage from an administrative perspective and easier for analysts to know which correlation searches are in-house.

<<<<

image::content_mgmt_01.png[]

== Scheduling

* How quickly do you need to be alerted?
* What kind of time window are you looking to capture?

If you think you need realtime, you probably don't.
Instead, run your search over a larger window than the schedule.
For example, a search runs every 20 minutes looking at an hour of data.
Use throttling to prevent duplicates.

<<<<

image::content_mgmt_02.png[]

== Notables & Risk

Notables and Risk are just modular alert actions.
With Notable events, you have the opportunity to use variables to present information to your analysts.

image::notable_01.png[]

<<<<

https://www.youtube.com/watch?v=9IG3zqvUqJY[Risk?]

Frankly this is a topic worthy of it's own talk.

== Drilldown Creation

The goal of a useful drilldown is to direct your analysts to additional relevant information.
With this in mind I don't find it to be particularly useful to just dump an analyst to information nearly identical to what's in the notable event.
With that said, a link to raw events can work in a pinch.

<<<<

With drilldown searches there are two main options to bring data back to the analyst:

* A | datamodel search
** Pro - Raw events!
** Con - Typically really slow
* A | tstats search
** Pro - Really quick
** Con - No raw events here, we're working with the fields within the datamodel itself

In some circumstances, you're working with data outside a datamodel, so a more traditional SPL search can make sense here.

<<<<

We already spoke to | tstats syntax above, but I would like to provide a quick template for utilizing | datamodel searches.

Base:

 |  datamodel <datamodel> <object in datamodel> search 

Filter:

 | search <field in datamodel>=<some value>

Putting it together:

 | datamodel Authentication Failed_Authentication search | search Authentication.user="$user$"

== Extra Credit

We didn't get into anything related to dynamic thresholding or extreme search.
These items are worthy of a talk themselves.
I did, however, want to include some resources and further reading for the adventurous.

=== Extreme Search!

Anything that's a static threshold or stdv can typically be converted into an Extreme Search context.
You can control how the context is generated and updated, giving you a self learning threshold on your searches.

http://conf.splunk.com/files/2016/slides/anomaly-hunting-with-splunk-software.pdf[Macy Cronkrite's .conf2016 talk]

http://www.georgestarcher.com/splunk-getting-extreme-part-one/[Starcher's eXtreme Search blog series]

=== Community

Join us on Slack or IRC, I'm beatus.
In Slack we have a handful of channels dedicated to security and advanced search techniques.

https://splunk-usergroups.signup.team/[Slack Signup]

https://wiki.splunk.com/Community:IRC[Splunk IRC]

https://answers.splunk.com/[Splunk Answers]

<<<<

https://github.com/brandonganem/splunk_correlation_srch_intro[Link to Slides]
